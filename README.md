<h1 align="center">Entity Relation Extraction in sentences ðŸ‘‹</h1>

## Environments 

### Requirements
- python==3.8
- pandas==1.1.5
- scikit-learn~=0.24.1
- transformers==4.10.0


### Hardware
The following specs were used to create the original solution.
- GPU(CUDA) : V100 

## Reproducing Submission
To reproduct my submission without retraining, do the following steps:
<!-- 1. [Installation](#installation)
2. [Dataset Preparation](#Dataset-Preparation)
3. [Make RGBY Images](#make-rgby-images) for official.
4. [Download Pretrained models](#pretrained-models)
5. [Inference](#inference)
6. [Make Submission](#make-submission) -->

## Installation
All requirements should be detailed in requirements.txt. Using Anaconda is strongly recommended.
```
pip install -r requirements.txt
```

## Dataset Preparation
All CSV files are already in data directory.


### Prepare Datasets
After downloading and converting datasets and baseline codes, the data directory is structured as:
```
â”œâ”€â”€ code
â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚    â””â”€â”€ load_data.cpython-38.pyc
â”‚   â”œâ”€â”€ wandb_imgaes
â”‚   â”‚    â”œâ”€â”€ eval.png 
â”‚   â”‚    â”œâ”€â”€ eval2.png
â”‚   â”‚    â”œâ”€â”€ train.png
â”‚   â”‚    â”œâ”€â”€ train2.png
â”‚   â”‚    â”œâ”€â”€ system.png
â”‚   â”‚    â”œâ”€â”€ system2.png
â”‚   â”‚    â””â”€â”€ system3.png
â”‚   â”œâ”€â”€ best_model
â”‚   â”œâ”€â”€ ensemble_csv
â”‚   â”œâ”€â”€ dict_label_to_num.pkl
â”‚   â”œâ”€â”€ dict_num_to_label.pkl
â”‚   â”œâ”€â”€ inference.py
â”‚   â”œâ”€â”€ load_data.py
â”‚   â”œâ”€â”€ bertmodel.py
â”‚   â”œâ”€â”€ logs
â”‚   â”œâ”€â”€ prediction
â”‚   â”‚    â””â”€â”€ sample_submission.csv
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ results
â”‚   â””â”€â”€ train.py
â””â”€â”€ dataset
    â”œâ”€â”€ test
    â”‚    â””â”€â”€ test_data.csv    
    â””â”€â”€ train
         â””â”€â”€ train.csv
```
#### Download Baseline code
To download baseline codes, run following command. The baseline codes will be located in *opt/ml/code*
```
$ !wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000075/data/code.tar.gz
```

#### Download Dataset
To download dataset, run following command. The dataset will be located in *opt/ml/dataset*
```
$ !wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000075/data/dataset.tar.gz
``` 
### Train models (GPU needed)
To train models, run following commands.
```
$ python train.py 
```
The expected training times are:

Model | GPUs | Batch Size | Training Epochs | Training Time
------------  | ------------- | ------------- | ------------- | -------------
KoELECTRA | v100 | 16 | 4 | 1h 51m 29s
XLM-RoBERTa-large | v100 | 27 | 4 | 2h 26m 52s
LSTM-RoBERTa-large | v100 | 32 | 5 |  2h 25m 14s
RoBERTa-large | v100 | 32 | 5 | 2h 5m 23s


### Inference & make submission
```
$ python inference.py
```

### Ensemble
```
$python ensemble.py --path='./ensemble_csv'
```

### Wandb graphs
#### eval graphs
<img src="[images/200x200.png](https://github.com/boostcampaitech2/klue-level2-nlp-03/blob/Main/wandb_imgaes/eval.png)"></a>
<img src="[images/200x200.png](https://github.com/boostcampaitech2/klue-level2-nlp-03/blob/Main/wandb_imgaes/eval2.png)"></a>
#### train graphs
<img src="[images/200x200.png](https://github.com/boostcampaitech2/klue-level2-nlp-03/blob/Main/wandb_imgaes/train.png)"></a>
<img src="[images/200x200.png](https://github.com/boostcampaitech2/klue-level2-nlp-03/blob/Main/wandb_imgaes/train2.png)"></a>
#### system graphs
<img src="[images/200x200.png](https://github.com/boostcampaitech2/klue-level2-nlp-03/blob/Main/wandb_imgaes/system.png)"></a>
<img src="[images/200x200.png](https://github.com/boostcampaitech2/klue-level2-nlp-03/blob/Main/wandb_imgaes/system2.png)"></a>
<img src="[images/200x200.png](https://github.com/boostcampaitech2/klue-level2-nlp-03/blob/Main/wandb_imgaes/system3.png)"></a>

## Code Contributors

This project exists thanks to all the people who contribute. 
<img src="https://sw6820.github.io/ai_boostcamp_lv3_3/" /></a>
